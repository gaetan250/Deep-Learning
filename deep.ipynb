{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226bebc7",
   "metadata": {},
   "source": [
    "# ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "data_path = \"SportsImageClassification\"\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Transformations ====\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)  \n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(f\"{data_path}/train\", transform=transform)\n",
    "valid_data = datasets.ImageFolder(f\"{data_path}/valid\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(f\"{data_path}/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(train_data.classes))  \n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"[{epoch+1}/{num_epochs}] Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\" Test Accuracy: {correct/total:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def generate_gradcam(image, model, class_names):\n",
    "    input_tensor = image.unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    activations.clear()\n",
    "    gradients.clear()\n",
    "\n",
    "    output = model(input_tensor)\n",
    "    pred_class = output.argmax().item()\n",
    "\n",
    "    model.zero_grad()\n",
    "    output[0, pred_class].backward()\n",
    "\n",
    "    grad = gradients[0]\n",
    "    act = activations[0]\n",
    "    weights = grad.mean(dim=(2, 3), keepdim=True)\n",
    "    cam = (weights * act).sum(dim=1).squeeze()\n",
    "    cam = F.relu(cam)\n",
    "    cam -= cam.min()\n",
    "    cam /= cam.max()\n",
    "    cam = cam.cpu().detach().numpy()\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "\n",
    "    img_np = image.permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    superimposed = np.clip(0.6 * img_np + 0.4 * heatmap, 0, 1)\n",
    "\n",
    "    return img_np, cam, superimposed, class_names[pred_class]\n",
    "\n",
    "activations = []\n",
    "gradients = []\n",
    "\n",
    "target_layer = model.layer4[1].conv2\n",
    "target_layer.register_forward_hook(lambda m, i, o: activations.append(o))\n",
    "target_layer.register_full_backward_hook(lambda m, gi, go: gradients.append(go[0]))\n",
    "\n",
    "images_to_plot = [41, 44]  \n",
    "\n",
    "fig, axs = plt.subplots(len(images_to_plot), 3, figsize=(10, 4 * len(images_to_plot)))\n",
    "\n",
    "for idx, image_idx in enumerate(images_to_plot):\n",
    "    image, label = test_data[image_idx]\n",
    "    original, cam_map, fusion, predicted_class = generate_gradcam(image, model, train_data.classes)\n",
    "\n",
    "    axs[idx, 0].imshow(original)\n",
    "    axs[idx, 0].set_title(\"Image originale\")\n",
    "    axs[idx, 1].imshow(cam_map, cmap=\"jet\")\n",
    "    axs[idx, 1].set_title(\"Carte Grad-CAM\")\n",
    "    axs[idx, 2].imshow(fusion)\n",
    "    axs[idx, 2].set_title(f\"Grad-CAM sur : {predicted_class}\")\n",
    "\n",
    "    for ax in axs[idx]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9494fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "torch.save(model.state_dict(), \"resnet_model.pth\")\n",
    "\n",
    "with open(\"class_names.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_data.classes, f)\n",
    "\n",
    "print(\" Modèle et classes sauvegardés pour Streamlit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Répartition train :\", Counter([label for _, label in train_data]))\n",
    "print(\"Répartition test  :\", Counter([label for _, label in test_data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_val = total_val = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in valid_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct_val += (preds == labels).sum().item()\n",
    "        total_val += labels.size(0)\n",
    "\n",
    "print(f\" Validation Accuracy: {correct_val / total_val:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2977b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(f\"{data_path}/train\", transform=transform)\n",
    "valid_data = datasets.ImageFolder(f\"{data_path}/valid\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(f\"{data_path}/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "def plot_class_distribution(data, title):\n",
    "    labels = [label for _, label in data]\n",
    "    counter = Counter(labels)\n",
    "    classes = data.classes\n",
    "    dist = {classes[i]: counter[i] for i in counter}\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(dist.keys(), dist.values())\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    total = sum(dist.values())\n",
    "    top3 = sorted(dist.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    bottom3 = sorted(dist.items(), key=lambda x: x[1])[:3]\n",
    "\n",
    "    print(f\" Nombre total d'images : {total}\")\n",
    "    print(\" Top 3 des classes les plus représentées :\")\n",
    "    for cls, count in top3:\n",
    "        print(f\"   - {cls} : {count} images\")\n",
    "    print(\" Top 3 des classes les moins représentées :\")\n",
    "    for cls, count in bottom3:\n",
    "        print(f\"   - {cls} : {count} images\")\n",
    "\n",
    "        \n",
    "print(\" Répartition des classes (train)\")\n",
    "plot_class_distribution(train_data, \"Répartition des classes (train)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39556110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(test_data.classes))))\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "accuracies = np.diag(cm_normalized)\n",
    "worst_indices = np.argsort(accuracies)[:10]  \n",
    "\n",
    "cm_worst = cm_normalized[np.ix_(worst_indices, worst_indices)]\n",
    "labels_worst = [test_data.classes[i] for i in worst_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_worst, annot=True, fmt=\".2f\", xticklabels=labels_worst, yticklabels=labels_worst, cmap=\"Reds\")\n",
    "plt.title(\"Matrice de confusion — Top 10 classes les moins bien prédites\")\n",
    "plt.xlabel(\"Classe prédite\")\n",
    "plt.ylabel(\"Classe réelle\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193340fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        for img, label, pred in zip(images, labels, preds):\n",
    "            if label != pred:\n",
    "                errors.append((img.cpu(), label.item(), pred.item()))\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for ax, (img, label, pred) in zip(axs.flat, errors[:9]):\n",
    "    ax.imshow(img.permute(1, 2, 0) * 0.5 + 0.5)  \n",
    "    ax.set_title(f\"True: {test_data.classes[label]}\\nPred: {test_data.classes[pred]}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c427ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "per_class_accuracy = {}\n",
    "\n",
    "for i, class_name in enumerate(test_data.classes):\n",
    "    mask = y_true == i\n",
    "    correct = (y_pred[mask] == i).sum()\n",
    "    total = mask.sum()\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    per_class_accuracy[class_name] = acc\n",
    "\n",
    "sorted_acc = sorted(per_class_accuracy.items(), key=lambda x: x[1])\n",
    "for cls, acc in sorted_acc[:10]:\n",
    "    print(f\"{cls:25s} : {acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b04cf",
   "metadata": {},
   "source": [
    "# Comparaison de différents modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a38c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "import copy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "498b9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, num_classes):\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    elif model_name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Modèle {model_name} non supporté.\")\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a49e5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs=5, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"[{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n",
    "        history.append(avg_loss)\n",
    "\n",
    "    train_time = time.time() - start_time\n",
    "    return model, history, train_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a998751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1).cpu()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "models_to_test = [\"efficientnet_b0\", \"vgg16\", \"resnet18\"]\n",
    "\n",
    "for name in models_to_test:\n",
    "    print(f\"\\n=== 🔍 Testing {name.upper()} ===\")\n",
    "\n",
    "    model = load_model(name, num_classes=len(train_data.classes))\n",
    "    model, loss_hist, train_time = train_model(model, train_loader, num_epochs=num_epochs)\n",
    "    acc, f1 = evaluate_model(model, test_loader)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\" Accuracy: {acc:.2%}\")\n",
    "    print(f\" F1-score: {f1:.4f}\")\n",
    "    print(f\" Train Time: {train_time:.2f}s\")\n",
    "    print(f\" Parameters: {total_params:,}\")\n",
    "\n",
    "    model_path = f\"saved_models/{name}_model.pth\"\n",
    "    class_path = f\"saved_models/{name}_classes.pkl\"\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    with open(class_path, \"wb\") as f:\n",
    "        pickle.dump(train_data.classes, f)\n",
    "\n",
    "    print(f\"Modèle sauvegardé sous {model_path}\")\n",
    "    print(f\"Classes sauvegardées sous {class_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de0e1a",
   "metadata": {},
   "source": [
    "# Overfitting check on ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd37ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=5, lr=1e-4, verbose=True):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[{epoch+1}/{num_epochs}] 🏋️ Train Loss: {avg_train_loss:.4f} | 🧪 Val Loss: {avg_val_loss:.4f} | 🎯 Val Acc: {val_acc:.2%}\")\n",
    "\n",
    "    train_time = time.time() - start_time\n",
    "    return model, train_losses, val_losses, val_accuracies, train_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeec0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(train_losses, val_losses, val_accuracies):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train vs Val Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, val_accuracies, label=\"Val Accuracy\", color='green')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Validation Accuracy\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482cc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"resnet18\", num_classes=len(train_data.classes))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model, train_losses, val_losses, val_accuracies, train_time = train_model(\n",
    "    model, train_loader, valid_loader, optimizer, num_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(train_losses, val_losses, val_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".envdeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
